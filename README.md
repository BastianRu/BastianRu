# Hi, I'm Sebastian ğŸ‘‹
### Computer Science Student | Machine Learning Core & AI Engineering

I am a passionate Computer Science student at **Universidad del Cauca**, currently in my 5th semester. My focus is on understanding the **mathematical and theoretical foundations** of Artificial Intelligence, moving beyond high-level abstractions to build systems from the ground up.

---

## ğŸ”¬ The "From Scratch" Philosophy
I believe that true mastery of AI comes from understanding the gradients. My work focuses on implementing core architectures using only low-level tensor operations, avoiding high-level "black box" libraries whenever possible.

- **Current Goal:** Full implementation of "Attention is All You Need" (Transformers) from scratch.
- **Academic Honors:** - ğŸ† **Two-time Academic Merit Scholarship** (Highest GPA in the program).
  - ğŸ¥‡ **National Academic Excellence Recognition (Ranked 1st in High School Standardized Exam).

---

## ğŸ› ï¸ Technical Arsenal

### **Machine Learning & AI**
* **Foundations:** Implementation of SGD, Backpropagation (manual), and Loss Functions (MSE, NLL, Cross-Entropy) from derivative definitions.
* **Probabilistic Modeling:** Experience with Probabilistic Language Models (Bengio 2003), Energy-Based Models (EBM), and N-gram models.
* **Deep Learning:** Building Multi-Layer Perceptrons (MLPs) from scalar autograd engines.

### **Tech Stack**
* **Languages:** Python (Expert), JavaScript, SQL.
* **Frameworks:** PyTorch (Low-level/NumPy-style usage).
* **AI Engineering:** Docker, Git/GitHub, Environment Management.
* **In Progress:** JAX, TensorFlow, ONNX, and Cloud Deployment (AWS/GCP).

### **Mathematics**
* **Linear Algebra:** Advanced proficiency.
* **Calculus:** Differential, Multivariable, and Vector Calculus.
* **Statistics:** Currently pursuing specialized certification in Statistics & Probability for Data Science.

---

## ğŸ“‚ Featured Projects

### ğŸ§  [Probabilistic Neural Language Model](https://github.com/BastianRu/Deep-Learning-Foundations-From-Scratch-Journal/blob/main/04-Probabilistic_Neural_Language_Model/ProbabilisticNeuralLModel.ipynb)
A PyTorch implementation of the seminal **Bengio et al. (2003)** paper. Focuses on word feature vectors (embeddings) and distributed representations before the Transformer era.

---

## ğŸ“ˆ My Learning Path
- ğŸ“– **Paper Reading:** Deeply studying "Attention is All You Need" and historical SOTA papers.
- ğŸ—ï¸ **Architectures:** Moving from MLPs to Transformers and GPT-style models.

